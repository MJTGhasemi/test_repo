{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ebe2e9d-685d-4ea3-ab7c-9589caaabff5",
   "metadata": {},
   "source": [
    "# Introduction to Large Language Model (LLM) Prompting\n",
    "In this lesson, you'll learn how to create effective prompts for large language models (LLMs) like OpenAI's GPT-4. This notebook will guide you through the setup, basic usage, and advanced techniques for prompt engineering.\n",
    "\n",
    "## Guidelines for Prompting\n",
    "Effective prompting is essential to get the desired output from LLMs. In this section, you'll practice two prompting principles and their related tactics to write effective prompts for large language models.\n",
    "\n",
    "\n",
    "\n",
    "## Setup\n",
    "Before we begin, we need to load the API key and relevant Python libraries.\n",
    "#### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bab499-9a50-4bd0-a622-1c914c6ccc29",
   "metadata": {},
   "source": [
    "In this course, we've provided some code that loads the OpenAI API key for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10efaaf7",
   "metadata": {},
   "source": [
    "\n",
    "The library needs to be configured with your account's secret key, which is available on the [OpenAI website](https://platform.openai.com/account/api-keys). \n",
    "\n",
    "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c382975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key = os.getenv('OPENAI_API_KEY'),\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3acefa8-f8f1-4ef8-932e-9bcefa142666",
   "metadata": {},
   "source": [
    "#### Helper function\n",
    "Throughout this course, we will use OpenAI's `gpt-4` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat). \n",
    "\n",
    "This helper function will make it easier to use prompts and look at the generated outputs.  \n",
    "**Note**: In May 2023, OpenAI updated gpt-4. The results you see in the notebook may be slightly different than those in the video. Some of the prompts have also been slightly modified to product the desired results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c42faefb",
   "metadata": {},
   "source": [
    "<font color='#FF6347'>**Note:**</font>\n",
    "### OpenAI Models\n",
    "\n",
    "As of 2024, OpenAI has developed several models, primarily focused on natural language processing (NLP) and artificial intelligence (AI). Here is a list of notable models developed by OpenAI:\n",
    "\n",
    "1. **GPT (Generative Pre-trained Transformer) Series:**\n",
    "    - **GPT:** The original model, introduced in 2018, demonstrated the ability to generate coherent text from a prompt.\n",
    "    - **GPT-2:** Released in 2019, this model improved upon the original with 1.5 billion parameters and demonstrated more advanced text generation capabilities.\n",
    "    - **GPT-3:** Launched in 2020, GPT-3 significantly expanded the model size to 175 billion parameters, becoming one of the largest and most powerful language models available.\n",
    "    - **GPT-3.5:** An interim update to GPT-3 with improved performance and efficiency.\n",
    "    - **GPT-4:** The latest iteration, released in 2023, further enhancing the capabilities with better context understanding, reasoning, and generation.\n",
    "    - **GPT-4O:** A specialized variant of GPT-4 optimized for specific use cases, offering improved performance and efficiency for targeted applications.  \n",
    "\n",
    "2. **Codex:** A model specialized for coding tasks, capable of understanding and generating code in various programming languages. This model powers GitHub Copilot.\n",
    "\n",
    "3. **DALL-E Series:**\n",
    "    - **DALL-E:** Introduced in 2021, capable of generating images from textual descriptions.\n",
    "    - **DALL-E 2:** An enhanced version with improved image quality and understanding of complex textual prompts.\n",
    "\n",
    "4. **CLIP (Contrastive Language-Image Pre-Training):** A model that connects vision and language, capable of understanding and generating textual descriptions for images.\n",
    "\n",
    "5. **Whisper:** A speech recognition model introduced to accurately transcribe and understand spoken language.\n",
    "\n",
    "These models represent significant advancements in AI, each tailored to specific tasks and capabilities, pushing the boundaries of what AI can achieve in natural language understanding, image generation, and code generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7dff174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399883c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt):\n",
    "    return chat_gpt(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4573495d",
   "metadata": {},
   "source": [
    "## Prompting Techniques\n",
    "\n",
    "### Temperature\n",
    "The temperature parameter controls the randomness of the model's output. A higher temperature results in more random completions, while a lower temperature results in more focused and deterministic completions.\n",
    "\n",
    "Try experimenting with different temperature settings:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8b32ac4",
   "metadata": {},
   "source": [
    "**Note:** This and all other lab notebooks of this course use OpenAI library version `0.27.0`. \n",
    "\n",
    "In order to use the OpenAI library version `1.0.0`, here is the code that you would use instead for the `get_completion` function:\n",
    "\n",
    "```python\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62298e-2181-4e73-bb40-77e20c655231",
   "metadata": {},
   "source": [
    "## Prompting Principles\n",
    "- **Principle 1: Write clear and specific instructions**\n",
    "- **Principle 2: Give the model time to “think”**\n",
    "\n",
    "### Tactics\n",
    "\n",
    "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "- Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87121316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To achieve desired model outputs, you should provide clear, specific instructions and not equate brevity with clarity as longer prompts can often lead to clearer and more detailed responses.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "You should express what you want a model to do by \n",
    "providing instructions that are as clear and \n",
    "specific as you can possibly make them. \n",
    "This will guide the model towards the desired output, \n",
    "and reduce the chances of receiving irrelevant \n",
    "or incorrect responses. Don't confuse writing a \n",
    "clear prompt with writing a short prompt. \n",
    "In many cases, longer prompts provide more clarity \n",
    "and context for the model, which can lead to \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "986636b2",
   "metadata": {},
   "source": [
    "Clear and specific instructions are crucial in guiding a model towards the desired output, and often longer prompts can provide more clarity and context, leading to more detailed and relevant outputs.\n",
    "\n",
    "To achieve desired model outputs, you should provide clear, specific instructions and not equate brevity with clarity as longer prompts can often lead to clearer and more detailed responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2798f3d-7618-4ac5-a6b2-3c69c537903d",
   "metadata": {},
   "source": [
    "#### Tactic 2: Ask for a structured output\n",
    "- JSON, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b50bbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```markdown\n",
      "| book_id | title               | author         | genre         |\n",
      "|---------|---------------------|----------------|---------------|\n",
      "| 1       | \"The Ocean's Echo\"  | John Caldwell  | Fantasy       |\n",
      "| 2       | \"Twisted Horizons\"  | Jane Milton    | Science Fiction |\n",
      "| 3       | \"Sweet Vengeance\"   | Sophie Bernard | Romance       |\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\ \n",
    "with their authors and genres. \n",
    "Provide them in jupyter markdown format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a71c4f-b1f1-4d67-ad5a-e49fc1e3147d",
   "metadata": {},
   "source": [
    "#### Tactic 3: Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ae612e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - While that's happening, grab a cup and put a tea bag in it.\n",
      "Step 3 - Once the water is hot enough, pour it over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - If you like, add some sugar or milk to taste.\n",
      "Step 7 - Enjoy your delicious cup of tea.\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\ \n",
    "water boiling. While that's happening, \\ \n",
    "grab a cup and put a tea bag in it. Once the water is \\ \n",
    "hot enough, just pour it over the tea bag. \\ \n",
    "Let it sit for a bit so the tea can steep. After a \\ \n",
    "few minutes, take out the tea bag. If you \\ \n",
    "like, you can add some sugar or milk to taste. \\ \n",
    "And that's it! You've got yourself a delicious \\ \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b6cc59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 2:\n",
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \\\n",
    "singing. It's a beautiful day to go for a \\ \n",
    "walk in the park. The flowers are blooming, and the \\ \n",
    "trees are swaying gently in the breeze. People \\ \n",
    "are out and about, enjoying the lovely weather. \\ \n",
    "Some are having picnics, while others are playing \\ \n",
    "games or simply relaxing on the grass. It's a \\ \n",
    "perfect day to spend time outdoors and appreciate the \\ \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 2:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5866b8-d8c7-4e19-93db-401315f64954",
   "metadata": {},
   "source": [
    "#### Tactic 4: \"Few-shot\" prompting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4f16513",
   "metadata": {},
   "source": [
    "### What is Few-Shot Prompting?\n",
    "Few-shot prompting is a technique used in natural language processing (NLP) where a language model, such as OpenAI's GPT-4, is provided with a small number of example inputs and corresponding outputs (known as \"shots\") to guide it in generating a response for a new, similar input. This approach leverages the model's ability to generalize from a limited set of examples to perform a task without requiring extensive fine-tuning or large datasets.\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Few-Shot Learning:** The model is provided with a few examples (typically 1-10) to learn the task. This contrasts with zero-shot learning, where the model is given no examples, and many-shot learning, where the model is trained on a large dataset.\n",
    "2. **Prompt Format:** The few-shot prompt includes the task description followed by several example input-output pairs, and finally the new input for which the model needs to generate an output.\n",
    "\n",
    "### Example:\n",
    "Suppose we want the model to translate English sentences to French. Here is how a few-shot prompt might look:\n",
    "\n",
    "**Prompt:**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdf22adf",
   "metadata": {},
   "source": [
    "Translate the following English sentences to French:\n",
    "\n",
    "English: How are you?\n",
    "French: Comment ça va?\n",
    "\n",
    "English: Good morning.\n",
    "French: Bonjour.\n",
    "\n",
    "English: Thank you.\n",
    "French: Merci.\n",
    "\n",
    "English: Where is the library?\n",
    "French: Où est la bibliothèque?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ce1540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: The mightiest oak tree started life as a fragile acorn, enduring countless storms and winters; the unyielding rock that withstands the ocean's waves was once but a grain of sand; the iron that carries the weight of the world was once a lump of ore, beaten and shaped under the blacksmith's hammer.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b550d24",
   "metadata": {},
   "source": [
    "### Benefits of Few-Shot Prompting:\n",
    "- **Flexibility:** Allows the model to adapt to a wide range of tasks without extensive retraining.\n",
    "- **Efficiency:** Requires fewer examples and less computational resources compared to training a model from scratch.\n",
    "- **Ease of Use:** Users can quickly create prompts with a few examples to guide the model.\n",
    "\n",
    "### Applications:\n",
    "- **Text Translation:** Translating text from one language to another.\n",
    "- **Text Summarization:** Summarizing long documents into concise summaries.\n",
    "- **Question Answering:** Answering questions based on provided context.\n",
    "- **Creative Writing:** Generating stories, poems, or other creative content.\n",
    "\n",
    "Few-shot prompting is a powerful technique that demonstrates the versatility and capability of large language models in performing a variety of tasks with minimal input data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7a8ee-1a2d-415d-8c10-500ecff24b10",
   "metadata": {},
   "source": [
    "### Principle 2: Give the model time to “think” \n",
    "\n",
    "#### Tactic 1: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e7d6860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "1 - In a quaint village, siblings Jack and Jill experience a mishap while fetching water from a hilltop well but continue their adventures with undimmed spirits.\n",
      "2 - Dans un charmant village, les frères et sœurs Jack et Jill vivent un incident en allant chercher de l'eau à un puits sur une colline, mais continuent leurs aventures avec un esprit indompté.\n",
      "3 - Jack, Jill\n",
      "4 - {\"french_summary\": \"Dans un charmant village, les frères et sœurs Jack et Jill vivent un incident en allant chercher de l'eau à un puits sur une colline, mais continuent leurs aventures avec un esprit indompté.\", \"num_names\": 2 }\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb1dcf-95f5-4ee1-8c25-8b2abd5f0f0d",
   "metadata": {},
   "source": [
    "#### Ask for output in a specified format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4222cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      "Summary: Siblings Jack and Jill go on a quest for water, trip and fall, but remain undaunted and continue exploring.\n",
      "Translation: Les frères et sœurs Jack et Jill partent en quête d'eau, trébuchent et tombent, mais restent imperturbables et continuent d'explorer.\n",
      "Names: Jack, Jill\n",
      "Output JSON: {\"french_summary\": \"Les frères et sœurs Jack et Jill partent en quête d'eau, trébuchent et tombent, mais restent imperturbables et continuent d'explorer.\", \"num_names\": 2}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(prompt_2)\n",
    "print(\"\\nCompletion for prompt 2:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec80fdb-92db-48f6-8f1d-b03c26385bad",
   "metadata": {},
   "source": [
    "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff5cc985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is correct.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322ebd9-0f8a-43aa-97fe-5eac70cdcc6a",
   "metadata": {},
   "source": [
    "#### Note that the student's solution is actually not correct.\n",
    "#### We can fix this by instructing the model to work out its own solution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "703f7003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Let x be the size of the installation in square feet.\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 10x\n",
      "Total cost: 100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "```\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "```\n",
      "No\n",
      "```\n",
      "Student grade:\n",
      "```\n",
      "Incorrect\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem including the final total. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a207eab-a1b1-47a5-b913-fe38086123d0",
   "metadata": {},
   "source": [
    "## Model Limitations: Hallucinations\n",
    "\n",
    "### What is Hallucination in Language Models?\n",
    "Hallucination in the context of language models refers to the phenomenon where the model generates text that is coherent and plausible but is factually incorrect or nonsensical. These hallucinations occur because the model generates responses based on patterns in the data it was trained on, rather than understanding or verifying the accuracy of the information.\n",
    "\n",
    "### Why Do Hallucinations Occur?\n",
    "1. **Training Data:** The model's responses are based on patterns learned from vast amounts of text data, which may include inaccuracies.\n",
    "2. **Autoregressive Nature:** Language models generate text one token at a time, and small errors can propagate and amplify as the text generation progresses.\n",
    "3. **Lack of Real-Time Knowledge:** Models like GPT-4 do not have access to real-time data and cannot verify facts in real-time.\n",
    "4. **Ambiguous Prompts:** Vague or poorly structured prompts can lead to hallucinations as the model tries to fill in the gaps.\n",
    "\n",
    "### How Can We Prevent Hallucinations?\n",
    "1. **Clear and Specific Prompts:** Ensure that prompts are clear, specific, and unambiguous. Providing detailed context can help the model generate more accurate responses.\n",
    "   - **Example:** Instead of asking, \"Tell me about the latest advancements in AI,\" specify, \"List the major AI advancements in 2023 related to natural language processing.\"\n",
    "2. **Use of Few-Shot or Zero-Shot Examples:** Provide examples in the prompt to guide the model towards the desired output.\n",
    "   - **Example:** When asking for a summary, provide a few examples of well-crafted summaries.\n",
    "3. **Verification and Validation:** Cross-check the model's responses against reliable sources. Incorporate a human-in-the-loop approach where experts review and validate the content.\n",
    "4. **Structured Outputs:** Request structured outputs, such as bullet points or specific formats, to minimize the chances of generating incorrect information.\n",
    "   - **Example:** Instead of asking for a general explanation, request a list of key points or a step-by-step guide.\n",
    "5. **Limitations Acknowledgment:** Inform users about the potential for hallucinations and encourage them to critically evaluate the generated content.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "556a41ed",
   "metadata": {},
   "source": [
    "### Example of Preventing Hallucinations:\n",
    "\n",
    "> **Prompt with Ambiguity:** Tell me about the history of AI.  \n",
    "> **Potential Hallucinated Response:** AI was invented in 1950 by Alan Turing, who also created the first computer.\n",
    "\n",
    "> **Improved Prompt:** Provide a brief timeline of significant milestones in the history of artificial intelligence, starting from the 1950s to the present day.  \n",
    "> **More Accurate Response:**  \n",
    "1950: Alan Turing proposes the Turing Test to evaluate machine intelligence.\n",
    "1956: The term \"artificial intelligence\" is coined at the Dartmouth Conference.\n",
    "1966: Joseph Weizenbaum develops ELIZA, one of the first chatbots.\n",
    "1997: IBM's Deep Blue defeats chess champion Garry Kasparov.\n",
    "2011: IBM Watson wins the quiz show Jeopardy!\n",
    "2023: Significant advancements in NLP with models like GPT-4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8243b8f6",
   "metadata": {},
   "source": [
    "Example: - Boie is a real company, the product name is not real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81c80919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AeroGlide UltraSlim Smart Toothbrush by Boie is a revolutionary oral care device designed to bring advanced technology to your daily dental care routine. It comes with ultra-soft, silver-infused bristles that not only thoroughly clean your teeth but also keeps your toothbrush cleaner and reduces the chances of bacteria growth.\n",
      "\n",
      "This smart toothbrush is known for its slim and flexible design which makes it easy to reach every corner of your mouth. Using sonic technology, it delivers 30,000 brush strokes per minute ensuring to eliminate plaque and other dental impurities more effectively than a manual toothbrush.\n",
      "\n",
      "The AeroGlide UltraSlim Smart Toothbrush also includes features such as built-in smart sensors and an automatic timer which makes sure that you brush for the dentist-recommended time of two minutes. This smart toothbrush also generates minimal noise during operation and comes with long-lasting battery life.\n",
      "\n",
      "Apart from these features, this smart toothbrush can also connect to an app on your smartphone via Bluetooth which provides feedback about your brushing habits, helps you learn advanced brushing techniques, and enables you to set custom brushing plans. \n",
      "\n",
      "Overall, the AeroGlide UltraSlim Smart Toothbrush is designed to provide superior oral care benefits while making brushing a more convenient and personalized experience.\n",
      "\n",
      "Please note that you should confirm the exact features and specifications of the product with the manufacturer or retailer as they may vary.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b56eb88f",
   "metadata": {},
   "source": [
    "<font color='#FF6347'>**Note:**</font> By following these strategies, we can reduce the occurrence of hallucinations and improve the reliability of the model's outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea88a6e-0141-4296-a73b-6b2282fe0de6",
   "metadata": {},
   "source": [
    "## Try experimenting on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02294fd1-bc42-416a-b0cb-34d6d22b20cd",
   "metadata": {},
   "source": [
    "#### Notes on using the OpenAI API outside of this classroom\n",
    "\n",
    "To install the OpenAI Python library:\n",
    "```\n",
    "!pip install openai\n",
    "```\n",
    "\n",
    "The library needs to be configured with your account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys). \n",
    "\n",
    "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n",
    " ```\n",
    " !export OPENAI_API_KEY='sk-...'\n",
    " ```\n",
    "\n",
    "Or, set `openai.api_key` to its value:\n",
    "\n",
    "```\n",
    "import openai\n",
    "openai.api_key = \"sk-...\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2ef0aa7-77e5-465e-a0ac-21c7156c9339",
   "metadata": {},
   "source": [
    "#### A note about the backslash\n",
    "- In the course, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters.\n",
    "- GPT models isn't really affected whether you insert newline characters or not.  But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
